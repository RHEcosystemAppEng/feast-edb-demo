{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset\n",
    "Generate dataset for the recommendation system plroblem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users sample:\n",
      "   user_id  age gender signup_date          preferences\n",
      "0        1   56      F  2023-09-28  Home,Books,Clothing\n",
      "1        2   36      M  2023-03-29          Electronics\n",
      "2        3   19      F  2023-10-21       Clothing,Books\n",
      "3        4   39      M  2023-12-11          Electronics\n",
      "4        5   45  Other  2023-09-28    Electronics,Books\n",
      "\n",
      "Items sample:\n",
      "   item_id  category  subcategory  ...  new_arrival  on_sale        arrival_date\n",
      "0        1    Sports  Team Sports  ...        False    False 2023-03-13 04:48:00\n",
      "1        2      Home      Kitchen  ...        False     True 2023-08-31 09:14:00\n",
      "2        3     Books      Science  ...        False    False 2023-01-02 12:40:00\n",
      "3        4  Clothing  Accessories  ...        False    False 2023-05-08 06:41:00\n",
      "4        5    Sports  Team Sports  ...        False    False 2023-05-27 08:28:00\n",
      "\n",
      "[5 rows x 10 columns]\n",
      "\n",
      "Interactions sample:\n",
      "   interaction_id  user_id  item_id  ... interaction_type rating  quantity\n",
      "0               1      382     1258  ...             view    NaN       NaN\n",
      "1               2      472     3771  ...         purchase    NaN       1.0\n",
      "2               3      669     1489  ...             view    NaN       NaN\n",
      "3               4      277     4743  ...             view    NaN       NaN\n",
      "4               5      365     2152  ...             view    NaN       NaN\n",
      "\n",
      "[5 rows x 7 columns]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ikatav/Projects/rec-sys-feast-edb/dataset_gen.py\", line 160, in <module>\n",
      "    pd.DataFrame(columns=['user_id', 'embedding', 'timestamp'], dtype={'user_id': 'int64', 'embedding': 'object', 'timestamp': 'datetime64[us]'}).to_parquet('feature_repo/data/dummy_user_embed.parquet', index=False)\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ikatav/miniconda3/envs/we/lib/python3.11/site-packages/pandas/core/frame.py\", line 704, in __init__\n",
      "    dtype = self._validate_dtype(dtype)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ikatav/miniconda3/envs/we/lib/python3.11/site-packages/pandas/core/generic.py\", line 516, in _validate_dtype\n",
      "    dtype = pandas_dtype(dtype)\n",
      "            ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ikatav/miniconda3/envs/we/lib/python3.11/site-packages/pandas/core/dtypes/common.py\", line 1645, in pandas_dtype\n",
      "    npdtype = np.dtype(dtype)\n",
      "              ^^^^^^^^^^^^^^^\n",
      "  File \"/home/ikatav/miniconda3/envs/we/lib/python3.11/site-packages/numpy/core/_internal.py\", line 61, in _usefields\n",
      "    names, formats, offsets, titles = _makenames_list(adict, align)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ikatav/miniconda3/envs/we/lib/python3.11/site-packages/numpy/core/_internal.py\", line 31, in _makenames_list\n",
      "    raise ValueError(\"entry not a 2- or 3- tuple\")\n",
      "ValueError: entry not a 2- or 3- tuple\n"
     ]
    }
   ],
   "source": [
    "!python3 dataset_gen.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Feature Store\n",
    "\n",
    "We run the `feast apply` command to register the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ikatav/miniconda3/envs/we/lib/python3.11/site-packages/feast/feature_view.py:48: DeprecationWarning: Entity value_type will be mandatory in the next release. Please specify a value_type for entity '__dummy'.\n",
      "  DUMMY_ENTITY = Entity(\n",
      "/home/ikatav/miniconda3/envs/we/lib/python3.11/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"vector_enabled\" in \"SqliteOnlineStoreConfig\" shadows an attribute in parent \"VectorStoreConfig\"\n",
      "  warnings.warn(\n",
      "/home/ikatav/miniconda3/envs/we/lib/python3.11/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"vector_len\" in \"SqliteOnlineStoreConfig\" shadows an attribute in parent \"VectorStoreConfig\"\n",
      "  warnings.warn(\n",
      "No project found in the repository. Using project name feast_edb_rec_sys defined in feature_store.yaml\n",
      "/home/ikatav/miniconda3/envs/we/lib/python3.11/site-packages/feast/entity.py:173: DeprecationWarning: Entity value_type will be mandatory in the next release. Please specify a value_type for entity '__dummy'.\n",
      "  entity = cls(\n",
      "/home/ikatav/miniconda3/envs/we/lib/python3.11/site-packages/feast/entity.py:173: DeprecationWarning: Entity value_type will be mandatory in the next release. Please specify a value_type for entity 'user'.\n",
      "  entity = cls(\n",
      "/home/ikatav/miniconda3/envs/we/lib/python3.11/site-packages/feast/entity.py:173: DeprecationWarning: Entity value_type will be mandatory in the next release. Please specify a value_type for entity 'item'.\n",
      "  entity = cls(\n",
      "Updated feature view \u001b[1m\u001b[33mitem_embedding\u001b[0m\n",
      "\tbatch_source: \u001b[1m\u001b[33mname: \"data/recommendation_items.parquet\"\n",
      "type: BATCH_FILE\n",
      "timestamp_field: \"arrival_date\"\n",
      "data_source_class_type: \"feast.infra.offline_stores.file_source.FileSource\"\n",
      "file_options {\n",
      "  file_format {\n",
      "    parquet_format {\n",
      "    }\n",
      "  }\n",
      "  uri: \"data/recommendation_items.parquet\"\n",
      "}\n",
      "\u001b[0m -> \u001b[1m\u001b[92mname: \"data/dummy_item_embed.parquet\"\n",
      "type: BATCH_FILE\n",
      "timestamp_field: \"timestamp\"\n",
      "data_source_class_type: \"feast.infra.offline_stores.file_source.FileSource\"\n",
      "file_options {\n",
      "  file_format {\n",
      "    parquet_format {\n",
      "    }\n",
      "  }\n",
      "  uri: \"data/dummy_item_embed.parquet\"\n",
      "}\n",
      "\u001b[0m\n",
      "\tstream_source: \u001b[1m\u001b[33mname: \"item_embed_push_source\"\n",
      "type: PUSH_SOURCE\n",
      "data_source_class_type: \"feast.data_source.PushSource\"\n",
      "batch_source {\n",
      "  name: \"data/recommendation_items.parquet\"\n",
      "  type: BATCH_FILE\n",
      "  timestamp_field: \"arrival_date\"\n",
      "  file_options {\n",
      "    file_format {\n",
      "      parquet_format {\n",
      "      }\n",
      "    }\n",
      "    uri: \"data/recommendation_items.parquet\"\n",
      "  }\n",
      "}\n",
      "\u001b[0m -> \u001b[1m\u001b[92mname: \"item_embed_push_source\"\n",
      "type: PUSH_SOURCE\n",
      "data_source_class_type: \"feast.data_source.PushSource\"\n",
      "batch_source {\n",
      "  name: \"data/dummy_item_embed.parquet\"\n",
      "  type: BATCH_FILE\n",
      "  timestamp_field: \"timestamp\"\n",
      "  file_options {\n",
      "    file_format {\n",
      "      parquet_format {\n",
      "      }\n",
      "    }\n",
      "    uri: \"data/dummy_item_embed.parquet\"\n",
      "  }\n",
      "}\n",
      "\u001b[0m\n",
      "Updated feature view \u001b[1m\u001b[33muser_embedding\u001b[0m\n",
      "\tbatch_source: \u001b[1m\u001b[33mname: \"data/recommendation_users.parquet\"\n",
      "type: BATCH_FILE\n",
      "timestamp_field: \"signup_date\"\n",
      "data_source_class_type: \"feast.infra.offline_stores.file_source.FileSource\"\n",
      "file_options {\n",
      "  file_format {\n",
      "    parquet_format {\n",
      "    }\n",
      "  }\n",
      "  uri: \"data/recommendation_users.parquet\"\n",
      "}\n",
      "\u001b[0m -> \u001b[1m\u001b[92mname: \"data/dummy_user_embed.parquet\"\n",
      "type: BATCH_FILE\n",
      "timestamp_field: \"timestamp\"\n",
      "data_source_class_type: \"feast.infra.offline_stores.file_source.FileSource\"\n",
      "file_options {\n",
      "  file_format {\n",
      "    parquet_format {\n",
      "    }\n",
      "  }\n",
      "  uri: \"data/dummy_user_embed.parquet\"\n",
      "}\n",
      "\u001b[0m\n",
      "\tstream_source: \u001b[1m\u001b[33mname: \"user_embed_push_source\"\n",
      "type: PUSH_SOURCE\n",
      "data_source_class_type: \"feast.data_source.PushSource\"\n",
      "batch_source {\n",
      "  name: \"data/recommendation_users.parquet\"\n",
      "  type: BATCH_FILE\n",
      "  timestamp_field: \"signup_date\"\n",
      "  file_options {\n",
      "    file_format {\n",
      "      parquet_format {\n",
      "      }\n",
      "    }\n",
      "    uri: \"data/recommendation_users.parquet\"\n",
      "  }\n",
      "}\n",
      "\u001b[0m -> \u001b[1m\u001b[92mname: \"user_embed_push_source\"\n",
      "type: PUSH_SOURCE\n",
      "data_source_class_type: \"feast.data_source.PushSource\"\n",
      "batch_source {\n",
      "  name: \"data/dummy_user_embed.parquet\"\n",
      "  type: BATCH_FILE\n",
      "  timestamp_field: \"timestamp\"\n",
      "  file_options {\n",
      "    file_format {\n",
      "      parquet_format {\n",
      "      }\n",
      "    }\n",
      "    uri: \"data/dummy_user_embed.parquet\"\n",
      "  }\n",
      "}\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[94mNo changes to infrastructure\n"
     ]
    }
   ],
   "source": [
    "!cd feature_repo/ ; feast plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ikatav/miniconda3/envs/we/lib/python3.11/site-packages/feast/feature_view.py:48: DeprecationWarning: Entity value_type will be mandatory in the next release. Please specify a value_type for entity '__dummy'.\n",
      "  DUMMY_ENTITY = Entity(\n",
      "/home/ikatav/miniconda3/envs/we/lib/python3.11/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"vector_enabled\" in \"SqliteOnlineStoreConfig\" shadows an attribute in parent \"VectorStoreConfig\"\n",
      "  warnings.warn(\n",
      "/home/ikatav/miniconda3/envs/we/lib/python3.11/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"vector_len\" in \"SqliteOnlineStoreConfig\" shadows an attribute in parent \"VectorStoreConfig\"\n",
      "  warnings.warn(\n",
      "No project found in the repository. Using project name feast_edb_rec_sys defined in feature_store.yaml\n",
      "Applying changes for project feast_edb_rec_sys\n",
      "Created project \u001b[1m\u001b[32mfeast_edb_rec_sys\u001b[0m\n",
      "Created entity \u001b[1m\u001b[32muser\u001b[0m\n",
      "Created entity \u001b[1m\u001b[32mitem\u001b[0m\n",
      "Created feature view \u001b[1m\u001b[32muser_features\u001b[0m\n",
      "Created feature view \u001b[1m\u001b[32mitem_embedding\u001b[0m\n",
      "Created feature view \u001b[1m\u001b[32mitem_features\u001b[0m\n",
      "Created feature view \u001b[1m\u001b[32muser_embedding\u001b[0m\n",
      "Created feature view \u001b[1m\u001b[32minteractions_features\u001b[0m\n",
      "Created feature service \u001b[1m\u001b[32minteraction_service\u001b[0m\n",
      "Created feature service \u001b[1m\u001b[32mmodel_v1\u001b[0m\n",
      "Created feature service \u001b[1m\u001b[32mitem_service\u001b[0m\n",
      "Created feature service \u001b[1m\u001b[32mmodel_v2\u001b[0m\n",
      "Created feature service \u001b[1m\u001b[32muser_service\u001b[0m\n",
      "\n",
      "Created sqlite table \u001b[1m\u001b[32mfeast_edb_rec_sys_interactions_features\u001b[0m\n",
      "Created sqlite table \u001b[1m\u001b[32mfeast_edb_rec_sys_item_features\u001b[0m\n",
      "Created sqlite table \u001b[1m\u001b[32mfeast_edb_rec_sys_user_features\u001b[0m\n",
      "Created sqlite table \u001b[1m\u001b[32mfeast_edb_rec_sys_item_embedding\u001b[0m\n",
      "Created sqlite table \u001b[1m\u001b[32mfeast_edb_rec_sys_user_embedding\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cd feature_repo/ ; feast apply "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feast import FeatureStore\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "store = FeatureStore(repo_path=\"feature_repo/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating datasets using Feast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using timestamp as the event timestamp. To specify a column explicitly, please name it event_timestamp.\n",
      "Using timestamp as the event timestamp. To specify a column explicitly, please name it event_timestamp.\n",
      "Using timestamp as the event timestamp. To specify a column explicitly, please name it event_timestamp.\n"
     ]
    }
   ],
   "source": [
    "from feast import FeatureService\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "# load feature services\n",
    "item_service = store.get_feature_service(\"item_service\")\n",
    "user_service = store.get_feature_service(\"user_service\")\n",
    "interaction_service = store.get_feature_service(\"interaction_service\")\n",
    "\n",
    "user_ids = list(range(1, 1_000))\n",
    "item_ids = list(range(1, 5_000))\n",
    "\n",
    "# select which entities to use\n",
    "item_entity_df = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        'item_id': item_ids,\n",
    "        'timestamp': [datetime(2025, 1, 1)] * len(item_ids) \n",
    "    }\n",
    ")\n",
    "user_entity_df = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        'user_id': user_ids,\n",
    "        'timestamp': [datetime(2025, 1, 1)] * len(user_ids) \n",
    "    }\n",
    ")\n",
    "item_user_interactions_df = pd.read_parquet('./feature_repo/data/interactions_item_user_ids.parquet')\n",
    "item_user_interactions_df['timestamp'] = datetime(2025, 1, 1)\n",
    "\n",
    "# retrive datasets for training\n",
    "item_df = store.get_historical_features(entity_df=item_entity_df, features=item_service).to_df()\n",
    "user_df = store.get_historical_features(entity_df=user_entity_df, features=user_service).to_df()\n",
    "interaction_df = store.get_historical_features(entity_df=item_user_interactions_df, features=interaction_service).to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import ItemEncoder, UserEncoder, TwoTowerModel, train_two_tower\n",
    "dim = 512\n",
    "\n",
    "item_encoder = ItemEncoder(dim)\n",
    "user_encoder = UserEncoder(dim)\n",
    "two_tower_model = TwoTowerModel(item_encoder=item_encoder, user_encoder=user_encoder)\n",
    "train_two_tower(two_tower_model, item_df, user_df, interaction_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch scoring\n",
    "Encode the items and users vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeded_items = item_encoder(item_df)\n",
    "item_df['embedding'] = embeded_items\n",
    "embeded_users = user_encoder(user_df)\n",
    "user_df['embedding'] = embeded_users\n",
    "\n",
    "# Push the new embedding to the offline and online store\n",
    "store.push('user_embed_push_source', item_df)\n",
    "store.push('item_embed_push_source', user_df)\n",
    "# store.push('user_embed_push_source', item_df[['item_id', 'embedding']])\n",
    "# store.push('item_embed_push_source', user_df[['user_id', 'embedding']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feast.data_source import PushMode\n",
    "import numpy as np\n",
    "# embeded_items = item_encoder(item_df)\n",
    "# embeded_users = user_encoder(user_df)\n",
    "item_embed_df = item_df[['item_id']]\n",
    "user_embed_df = user_df[['user_id']]\n",
    "\n",
    "item_embed_df['embedding'] = [[1.1, 2.2]] * len(item_embed_df)\n",
    "user_embed_df['embedding'] = [[1.1, 2.2]] * len(user_embed_df)\n",
    "\n",
    "item_embed_df['timestamp'] = datetime.now()\n",
    "user_embed_df['timestamp'] = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4999 entries, 0 to 4998\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   item_id       4999 non-null   int64         \n",
      " 1   timestamp     4999 non-null   datetime64[us]\n",
      " 2   category      4999 non-null   object        \n",
      " 3   subcategory   4999 non-null   object        \n",
      " 4   price         4999 non-null   float64       \n",
      " 5   avg_rating    4999 non-null   float64       \n",
      " 6   num_ratings   4999 non-null   int64         \n",
      " 7   popular       4999 non-null   bool          \n",
      " 8   new_arrival   4999 non-null   bool          \n",
      " 9   on_sale       4999 non-null   bool          \n",
      " 10  embedding     4999 non-null   object        \n",
      " 11  arrival_date  4999 non-null   datetime64[us]\n",
      "dtypes: bool(3), datetime64[us](2), float64(2), int64(2), object(3)\n",
      "memory usage: 366.3+ KB\n"
     ]
    }
   ],
   "source": [
    "item_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowNotImplementedError",
     "evalue": "Unsupported cast from int64 to null using function cast_null",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowNotImplementedError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Push the new embedding to the offline and online store\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m store\u001b[38;5;241m.\u001b[39mpush(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_embed_push_source\u001b[39m\u001b[38;5;124m'\u001b[39m, item_embed_df, to\u001b[38;5;241m=\u001b[39mPushMode\u001b[38;5;241m.\u001b[39mONLINE_AND_OFFLINE)\n\u001b[1;32m      3\u001b[0m store\u001b[38;5;241m.\u001b[39mpush(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_embed_push_source\u001b[39m\u001b[38;5;124m'\u001b[39m, user_embed_df, to\u001b[38;5;241m=\u001b[39mPushMode\u001b[38;5;241m.\u001b[39mONLINE_AND_OFFLINE)\n",
      "File \u001b[0;32m~/miniconda3/envs/we/lib/python3.11/site-packages/feast/feature_store.py:1483\u001b[0m, in \u001b[0;36mFeatureStore.push\u001b[0;34m(self, push_source_name, df, allow_registry_cache, to)\u001b[0m\n\u001b[1;32m   1479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_to_online_store(\n\u001b[1;32m   1480\u001b[0m         fv\u001b[38;5;241m.\u001b[39mname, df, allow_registry_cache\u001b[38;5;241m=\u001b[39mallow_registry_cache\n\u001b[1;32m   1481\u001b[0m     )\n\u001b[1;32m   1482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m to \u001b[38;5;241m==\u001b[39m PushMode\u001b[38;5;241m.\u001b[39mOFFLINE \u001b[38;5;129;01mor\u001b[39;00m to \u001b[38;5;241m==\u001b[39m PushMode\u001b[38;5;241m.\u001b[39mONLINE_AND_OFFLINE:\n\u001b[0;32m-> 1483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_to_offline_store(\n\u001b[1;32m   1484\u001b[0m         fv\u001b[38;5;241m.\u001b[39mname, df, allow_registry_cache\u001b[38;5;241m=\u001b[39mallow_registry_cache\n\u001b[1;32m   1485\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/we/lib/python3.11/site-packages/feast/feature_store.py:1645\u001b[0m, in \u001b[0;36mFeatureStore.write_to_offline_store\u001b[0;34m(self, feature_view_name, df, allow_registry_cache, reorder_columns)\u001b[0m\n\u001b[1;32m   1642\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mreindex(columns\u001b[38;5;241m=\u001b[39msource_columns)\n\u001b[1;32m   1644\u001b[0m table \u001b[38;5;241m=\u001b[39m pa\u001b[38;5;241m.\u001b[39mTable\u001b[38;5;241m.\u001b[39mfrom_pandas(df)\n\u001b[0;32m-> 1645\u001b[0m provider\u001b[38;5;241m.\u001b[39mingest_df_to_offline_store(feature_view, table)\n",
      "File \u001b[0;32m~/miniconda3/envs/we/lib/python3.11/site-packages/feast/infra/passthrough_provider.py:416\u001b[0m, in \u001b[0;36mPassthroughProvider.ingest_df_to_offline_store\u001b[0;34m(self, feature_view, table)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_view\u001b[38;5;241m.\u001b[39mbatch_source\u001b[38;5;241m.\u001b[39mfield_mapping \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m     table \u001b[38;5;241m=\u001b[39m _run_pyarrow_field_mapping(\n\u001b[1;32m    413\u001b[0m         table, feature_view\u001b[38;5;241m.\u001b[39mbatch_source\u001b[38;5;241m.\u001b[39mfield_mapping\n\u001b[1;32m    414\u001b[0m     )\n\u001b[0;32m--> 416\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffline_write_batch(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepo_config, feature_view, table, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/we/lib/python3.11/site-packages/feast/infra/passthrough_provider.py:219\u001b[0m, in \u001b[0;36mPassthroughProvider.offline_write_batch\u001b[0;34m(self, config, feature_view, data, progress)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moffline_write_batch\u001b[39m(\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    213\u001b[0m     config: RepoConfig,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m     progress: Optional[Callable[[\u001b[38;5;28mint\u001b[39m], Any]],\n\u001b[1;32m    217\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffline_store:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffline_store\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39moffline_write_batch(\n\u001b[1;32m    220\u001b[0m             config, feature_view, data, progress\n\u001b[1;32m    221\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/we/lib/python3.11/site-packages/feast/infra/offline_stores/dask.py:486\u001b[0m, in \u001b[0;36mDaskOfflineStore.offline_write_batch\u001b[0;34m(config, feature_view, table, progress)\u001b[0m\n\u001b[1;32m    482\u001b[0m prev_table \u001b[38;5;241m=\u001b[39m pyarrow\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m    483\u001b[0m     path, filesystem\u001b[38;5;241m=\u001b[39mfilesystem, memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    484\u001b[0m )\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m table\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m!=\u001b[39m prev_table\u001b[38;5;241m.\u001b[39mschema:\n\u001b[0;32m--> 486\u001b[0m     table \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mcast(prev_table\u001b[38;5;241m.\u001b[39mschema)\n\u001b[1;32m    487\u001b[0m new_table \u001b[38;5;241m=\u001b[39m pyarrow\u001b[38;5;241m.\u001b[39mconcat_tables([table, prev_table])\n\u001b[1;32m    488\u001b[0m writer \u001b[38;5;241m=\u001b[39m pyarrow\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mParquetWriter(\n\u001b[1;32m    489\u001b[0m     path, table\u001b[38;5;241m.\u001b[39mschema, filesystem\u001b[38;5;241m=\u001b[39mfilesystem\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/we/lib/python3.11/site-packages/pyarrow/table.pxi:4683\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.cast\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/we/lib/python3.11/site-packages/pyarrow/table.pxi:593\u001b[0m, in \u001b[0;36mpyarrow.lib.ChunkedArray.cast\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/we/lib/python3.11/site-packages/pyarrow/compute.py:405\u001b[0m, in \u001b[0;36mcast\u001b[0;34m(arr, target_type, safe, options, memory_pool)\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m         options \u001b[38;5;241m=\u001b[39m CastOptions\u001b[38;5;241m.\u001b[39msafe(target_type)\n\u001b[0;32m--> 405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call_function(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcast\u001b[39m\u001b[38;5;124m\"\u001b[39m, [arr], options, memory_pool)\n",
      "File \u001b[0;32m~/miniconda3/envs/we/lib/python3.11/site-packages/pyarrow/_compute.pyx:598\u001b[0m, in \u001b[0;36mpyarrow._compute.call_function\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/we/lib/python3.11/site-packages/pyarrow/_compute.pyx:393\u001b[0m, in \u001b[0;36mpyarrow._compute.Function.call\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/we/lib/python3.11/site-packages/pyarrow/error.pxi:155\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/we/lib/python3.11/site-packages/pyarrow/error.pxi:92\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowNotImplementedError\u001b[0m: Unsupported cast from int64 to null using function cast_null"
     ]
    }
   ],
   "source": [
    "# Push the new embedding to the offline and online store\n",
    "store.push('item_embed_push_source', item_embed_df, to=PushMode.ONLINE_AND_OFFLINE)\n",
    "store.push('user_embed_push_source', user_embed_df, to=PushMode.ONLINE_AND_OFFLINE)\n",
    "# store.push('user_embed_push_source', item_df[['item_id', 'embedding']])\n",
    "# store.push('item_embed_push_source', user_df[['user_id', 'embedding']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4999 entries, 0 to 4998\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   item_id    4999 non-null   int64         \n",
      " 1   embedding  4999 non-null   object        \n",
      " 2   timestamp  4999 non-null   datetime64[us]\n",
      "dtypes: datetime64[us](1), int64(1), object(1)\n",
      "memory usage: 117.3+ KB\n"
     ]
    }
   ],
   "source": [
    "item_embed_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [1.1, 2.2]\n",
       "1       [1.1, 2.2]\n",
       "2       [1.1, 2.2]\n",
       "3       [1.1, 2.2]\n",
       "4       [1.1, 2.2]\n",
       "           ...    \n",
       "4994    [1.1, 2.2]\n",
       "4995    [1.1, 2.2]\n",
       "4996    [1.1, 2.2]\n",
       "4997    [1.1, 2.2]\n",
       "4998    [1.1, 2.2]\n",
       "Name: embedding, Length: 4999, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_df['embedding']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Materialize\n",
    "Materialization generates the latest values for each entity key in the online store and creates a time-based index to enhance retrieval speed.\n",
    "The `materialize-incremental `command materializes the offline store initially and, on subsequent runs, ingests only new data and updates the store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.materialize_incremental(datetime.now() - timedelta(days=365 * 5), feature_views=['item_embedding', 'user_embedding'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Existing User Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New User Case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feast import FeatureStore\n",
    "\n",
    "store = FeatureStore(repo_path=\".\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Get the latest feature values for unique entities\n",
    "entity_df = pd.DataFrame.from_dict({\"driver_id\": [1001, 1002, 1003, 1004, 1005],})\n",
    "entity_df[\"event_timestamp\"] = pd.to_datetime(\"now\", utc=True)\n",
    "training_df = store.get_historical_features(\n",
    "    entity_df=entity_df, features=store.get_feature_service(\"model_v2\"),\n",
    ").to_df()\n",
    "\n",
    "# Make batch predictions\n",
    "# predictions = model.predict(training_df)\n",
    "print(training_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "we",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
