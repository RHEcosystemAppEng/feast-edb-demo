{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset\n",
    "Generate dataset for the recommendation system plroblem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users sample:\n",
      "   user_id  age gender signup_date          preferences\n",
      "0        1   56      F  2023-09-28  Home,Books,Clothing\n",
      "1        2   36      M  2023-03-29          Electronics\n",
      "2        3   19      F  2023-10-21       Clothing,Books\n",
      "3        4   39      M  2023-12-11          Electronics\n",
      "4        5   45  Other  2023-09-28    Electronics,Books\n",
      "\n",
      "Items sample:\n",
      "   item_id  category  subcategory  ...  new_arrival  on_sale        arrival_date\n",
      "0        1    Sports  Team Sports  ...        False    False 2023-03-13 04:48:00\n",
      "1        2      Home      Kitchen  ...        False     True 2023-08-31 09:14:00\n",
      "2        3     Books      Science  ...        False    False 2023-01-02 12:40:00\n",
      "3        4  Clothing  Accessories  ...        False    False 2023-05-08 06:41:00\n",
      "4        5    Sports  Team Sports  ...        False    False 2023-05-27 08:28:00\n",
      "\n",
      "[5 rows x 10 columns]\n",
      "\n",
      "Interactions sample:\n",
      "   interaction_id  user_id  item_id  ... interaction_type rating  quantity\n",
      "0               1      382     1258  ...             view    NaN       NaN\n",
      "1               2      472     3771  ...         purchase    NaN       1.0\n",
      "2               3      669     1489  ...             view    NaN       NaN\n",
      "3               4      277     4743  ...             view    NaN       NaN\n",
      "4               5      365     2152  ...             view    NaN       NaN\n",
      "\n",
      "[5 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "!python3 dataset_gen.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Feature Store\n",
    "\n",
    "We run the `feast apply` command to register the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94mNo changes to registry\n",
      "\u001b[1m\u001b[94mNo changes to infrastructure\n"
     ]
    }
   ],
   "source": [
    "!cd feature_repo/ ; feast plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[94mNo changes to registry\n",
      "\u001b[1m\u001b[94mNo changes to infrastructure\n"
     ]
    }
   ],
   "source": [
    "!cd feature_repo/ ; feast apply "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feast import FeatureStore\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "store = FeatureStore(repo_path=\"feature_repo/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating datasets using Feast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using timestamp as the event timestamp. To specify a column explicitly, please name it event_timestamp.\n",
      "Using timestamp as the event timestamp. To specify a column explicitly, please name it event_timestamp.\n",
      "Using timestamp as the event timestamp. To specify a column explicitly, please name it event_timestamp.\n"
     ]
    }
   ],
   "source": [
    "from feast import FeatureService\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "# load feature services\n",
    "item_service = store.get_feature_service(\"item_service\")\n",
    "user_service = store.get_feature_service(\"user_service\")\n",
    "interaction_service = store.get_feature_service(\"interaction_service\")\n",
    "\n",
    "user_ids = list(range(1, 1_000))\n",
    "item_ids = list(range(1, 5_000))\n",
    "\n",
    "# select which entities to use\n",
    "item_entity_df = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        'item_id': item_ids,\n",
    "        'timestamp': [datetime(2025, 1, 1)] * len(item_ids) \n",
    "    }\n",
    ")\n",
    "user_entity_df = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        'user_id': user_ids,\n",
    "        'timestamp': [datetime(2025, 1, 1)] * len(user_ids) \n",
    "    }\n",
    ")\n",
    "item_user_interactions_df = pd.read_parquet('./feature_repo/data/interactions_item_user_ids.parquet')\n",
    "item_user_interactions_df['timestamp'] = datetime(2025, 1, 1)\n",
    "\n",
    "# retrive datasets for training\n",
    "item_df = store.get_historical_features(entity_df=item_entity_df, features=item_service).to_df()\n",
    "user_df = store.get_historical_features(entity_df=user_entity_df, features=user_service).to_df()\n",
    "interaction_df = store.get_historical_features(entity_df=item_user_interactions_df, features=interaction_service).to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import ItemEncoder, UserEncoder, TwoTowerModel, train_two_tower\n",
    "dim = 512\n",
    "\n",
    "item_encoder = ItemEncoder(dim)\n",
    "user_encoder = UserEncoder(dim)\n",
    "two_tower_model = TwoTowerModel(item_encoder=item_encoder, user_encoder=user_encoder)\n",
    "train_two_tower(two_tower_model, item_df, user_df, interaction_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch scoring\n",
    "Encode the items and users vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeded_items = item_encoder(item_df)\n",
    "item_df['embedding'] = embeded_items\n",
    "embeded_users = user_encoder(user_df)\n",
    "user_df['embedding'] = embeded_users\n",
    "\n",
    "# Push the new embedding to the offline and online store\n",
    "store.push('user_embed_push_source', item_df)\n",
    "store.push('item_embed_push_source', user_df)\n",
    "# store.push('user_embed_push_source', item_df[['item_id', 'embedding']])\n",
    "# store.push('item_embed_push_source', user_df[['user_id', 'embedding']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Materialize\n",
    "Materialization generates the latest values for each entity key in the online store and creates a time-based index to enhance retrieval speed.\n",
    "The `materialize-incremental `command materializes the offline store initially and, on subsequent runs, ingests only new data and updates the store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.materialize_incremental(datetime.now() - timedelta(days=365 * 5), feature_views=['item_embedding', 'user_embedding'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Existing User Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New User Case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feast import FeatureStore\n",
    "\n",
    "store = FeatureStore(repo_path=\".\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Get the latest feature values for unique entities\n",
    "entity_df = pd.DataFrame.from_dict({\"driver_id\": [1001, 1002, 1003, 1004, 1005],})\n",
    "entity_df[\"event_timestamp\"] = pd.to_datetime(\"now\", utc=True)\n",
    "training_df = store.get_historical_features(\n",
    "    entity_df=entity_df, features=store.get_feature_service(\"model_v2\"),\n",
    ").to_df()\n",
    "\n",
    "# Make batch predictions\n",
    "# predictions = model.predict(training_df)\n",
    "print(training_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "we",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
